{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:30.149829Z",
     "iopub.status.busy": "2022-04-12T03:24:30.149453Z",
     "iopub.status.idle": "2022-04-12T03:24:35.227030Z",
     "shell.execute_reply": "2022-04-12T03:24:35.226278Z",
     "shell.execute_reply.started": "2022-04-12T03:24:30.149749Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved\n",
    "# as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of \n",
    "# the current session\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files\n",
    "# under the input directory\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.applications.efficientnet as efn\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:35.228766Z",
     "iopub.status.busy": "2022-04-12T03:24:35.228500Z",
     "iopub.status.idle": "2022-04-12T03:24:35.235932Z",
     "shell.execute_reply": "2022-04-12T03:24:35.234113Z",
     "shell.execute_reply.started": "2022-04-12T03:24:35.228731Z"
    }
   },
   "outputs": [],
   "source": [
    "image_h = 128\n",
    "image_w = 128\n",
    "sample_size = 7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:35.237817Z",
     "iopub.status.busy": "2022-04-12T03:24:35.237395Z",
     "iopub.status.idle": "2022-04-12T03:24:35.254227Z",
     "shell.execute_reply": "2022-04-12T03:24:35.253514Z",
     "shell.execute_reply.started": "2022-04-12T03:24:35.237782Z"
    }
   },
   "outputs": [],
   "source": [
    "#print all file names\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename)) #end printing all file names\n",
    "\n",
    "train_img_dir = '/kaggle/input/happy-whale-and-dolphin/train_images'\n",
    "test_img_dir = '/kaggle/input/happy-whale-and-dolphin/test_images'\n",
    "sub_path = '/kaggle/input/happy-whale-and-dolphin/sample_submission.csv'\n",
    "train_path = '/kaggle/input/happy-whale-and-dolphin/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:39.004039Z",
     "iopub.status.busy": "2022-04-12T03:24:39.003431Z",
     "iopub.status.idle": "2022-04-12T03:24:39.192846Z",
     "shell.execute_reply": "2022-04-12T03:24:39.192114Z",
     "shell.execute_reply.started": "2022-04-12T03:24:39.004000Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "train_df.loc[train_df.species == \"bottlenose_dolpin\", \"species\"] = \"bottlenose_dolphin\"\n",
    "train_df.loc[train_df.species == \"kiler_whale\", \"species\"] = \"killer_whale\"\n",
    "train_df.loc[train_df.species == \"globis\", \"species\"] = \"short_finned_pilot_whale\"\n",
    "train_df.loc[train_df.species == \"pilot_whale\", \"species\"] = \"short_finned_pilot_whale\"\n",
    "train_df.loc[train_df.species == \"beluga\", \"species\"] = \"beluga_whale\"\n",
    "train_df.loc[train_df.species.str.contains(\"whale\")==True, \"label\"] = \"whale\"\n",
    "train_df.loc[train_df.species.str.contains(\"dolphin\")==True, \"label\"] = \"dolphin\"\n",
    "#the following can also be used however pd.np is deprecated in the future version \n",
    "# train_df['label'] = pd.np.where(train_df.species.str.contains(\"whale\"), \"whale\",\n",
    "#                    pd.np.where(train_df.species.str.contains(\"dolphin\"), \"dolphin\",\"task\"))\n",
    "train_df_all = train_df\n",
    "train_df = train_df.head(sample_size)\n",
    "print(len(train_df['species'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:42.380910Z",
     "iopub.status.busy": "2022-04-12T03:24:42.380055Z",
     "iopub.status.idle": "2022-04-12T03:24:43.009262Z",
     "shell.execute_reply": "2022-04-12T03:24:43.008531Z",
     "shell.execute_reply.started": "2022-04-12T03:24:42.380862Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['image_path'] = train_img_dir+'/'+train_df['image']\n",
    "list_of_test_image_paths = glob.glob(test_img_dir+'/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Label to neumeric lableing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:46.125471Z",
     "iopub.status.busy": "2022-04-12T03:24:46.125224Z",
     "iopub.status.idle": "2022-04-12T03:24:46.134849Z",
     "shell.execute_reply": "2022-04-12T03:24:46.134051Z",
     "shell.execute_reply.started": "2022-04-12T03:24:46.125442Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_df['species'].unique()))\n",
    "list_of_species = train_df['species'].unique()\n",
    "print(train_df['species'].unique())\n",
    "species_to_neumeric = dict()\n",
    "for i in range(0,len(list_of_species)):\n",
    "    species_to_neumeric[list_of_species[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:49.754749Z",
     "iopub.status.busy": "2022-04-12T03:24:49.754030Z",
     "iopub.status.idle": "2022-04-12T03:24:49.767401Z",
     "shell.execute_reply": "2022-04-12T03:24:49.766417Z",
     "shell.execute_reply.started": "2022-04-12T03:24:49.754713Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_df['individual_id'].unique()))\n",
    "list_of_ids = train_df['individual_id'].unique()\n",
    "ids_to_neumeric = dict()\n",
    "for i in range(0,len(list_of_ids)):\n",
    "    ids_to_neumeric[list_of_ids[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pre-Processing\n",
    "1. Resizing the image\n",
    "2. Converting the colored image to greyscale image may be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function to resize each image \n",
    "# def resize_images(path,image_w,image_h):#n_w =new width n_h = new_height\n",
    "#     img = tf.io.read_file(path)\n",
    "# #     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     img = tf.image.decode_jpeg(img, channels=3)#can decode to another format \n",
    "#     img = tf.image.resize(img, [image_w, image_h])\n",
    "#     return img\n",
    "# #concern After resizing it what we can do should we store the image to a new directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate the images and resize and store in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = len(train_df)\n",
    "# image_size = 128\n",
    "# image_train = np.empty((N, image_size, image_size, 3), dtype=np.uint8)\n",
    "# # loop through the images from the images ids from the target\\id dataset\n",
    "# # then grab the cooresponding image from disk, pre-process, and store in matrix in memory\n",
    "# for index,row in train_df.iterrows():\n",
    "#     re_img = resize_images(row.image_path,image_size,image_size)\n",
    "# #     image_train[i, :, :, :] = re_img\n",
    "# #     image = plt.imread(re_img) #after resizing It could not be plot \n",
    "#     #hence used tf casting to plot the image\n",
    "#     image = tf.cast(re_img, np.uint8)\n",
    "#     print((re_img.shape))\n",
    "#     plt.imshow(image)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test data generation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:24:56.251841Z",
     "iopub.status.busy": "2022-04-12T03:24:56.251037Z",
     "iopub.status.idle": "2022-04-12T03:24:56.261093Z",
     "shell.execute_reply": "2022-04-12T03:24:56.260360Z",
     "shell.execute_reply.started": "2022-04-12T03:24:56.251792Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_data_genration(train_df):#takes data frame input\n",
    "    train_image_list = []\n",
    "    for index,row in tqdm(train_df.iterrows()):\n",
    "    #     img = tf.io.read_file(row.image_path)\n",
    "    #     img = tf.image.decode_jpeg(img, channels=3)#can decode to another format \n",
    "    #     img = tf.image.resize(img, [128, 128])\n",
    "        img = tf.keras.preprocessing.image.load_img(row.image_path, target_size=(image_h,image_w,3), grayscale=False)\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img/255\n",
    "        train_image_list.append(img)\n",
    "    X_train = np.array(train_image_list)\n",
    "    return X_train\n",
    "def test_data_generation(list_of_test_image_paths,f_t_num): #takes the image directory array and number of images\n",
    "    test_image_list = []\n",
    "    for i in tqdm(range(0,f_t_num)):\n",
    "        img = tf.keras.preprocessing.image.load_img(list_of_test_image_paths[i],\n",
    "                                                    target_size=(image_h,image_w,3), grayscale=False)\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img/255\n",
    "        test_image_list.append(img)\n",
    "    X_T = np.array(test_image_list)\n",
    "    return X_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T03:25:05.905881Z",
     "iopub.status.busy": "2022-04-12T03:25:05.905000Z",
     "iopub.status.idle": "2022-04-12T03:35:35.104679Z",
     "shell.execute_reply": "2022-04-12T03:35:35.103918Z",
     "shell.execute_reply.started": "2022-04-12T03:25:05.905832Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_data_genration(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model For Identifying Whale and Dolphin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T04:25:25.181864Z",
     "iopub.status.busy": "2022-04-12T04:25:25.181535Z",
     "iopub.status.idle": "2022-04-12T04:25:25.266127Z",
     "shell.execute_reply": "2022-04-12T04:25:25.265052Z",
     "shell.execute_reply.started": "2022-04-12T04:25:25.181776Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [image_h, image_w]\n",
    "dense_layer_size = len(species_to_neumeric.values())\n",
    "model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(*IMAGE_SIZE, 3),\n",
    "                                                weights='imagenet',\n",
    "                                                include_top=False,classes=species_to_neumeric.values()),\n",
    "                             L.GlobalAveragePooling2D(),\n",
    "                             L.Flatten(),\n",
    "                             L.Dense(512, activation='relu'),\n",
    "                             L.Dense(dense_layer_size, activation='softmax')])\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for individual Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T18:45:21.223225Z",
     "iopub.status.busy": "2022-04-11T18:45:21.222946Z",
     "iopub.status.idle": "2022-04-11T18:45:29.230811Z",
     "shell.execute_reply": "2022-04-11T18:45:29.229966Z",
     "shell.execute_reply.started": "2022-04-11T18:45:21.223194Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [image_h, image_w]\n",
    "dense_layer_size = len(ids_to_neumeric.values())\n",
    "model_ind = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(*IMAGE_SIZE, 3),\n",
    "                                                weights='imagenet',\n",
    "                                                include_top=False,classes=ids_to_neumeric.values()),\n",
    "                             L.GlobalAveragePooling2D(),\n",
    "                             L.Flatten(),\n",
    "                             L.Dense(512, activation='relu'),\n",
    "                             L.Dense(dense_layer_size, activation='softmax')])\n",
    "model_ind.compile(optimizer='adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "model_ind.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neumerical Label to Categorical for Whale & Dolphin Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_as_label = train_df['species'].values\n",
    "species_label_list = []\n",
    "for species in species_as_label:\n",
    "    species_label_list.append(species_to_neumeric[species])\n",
    "# label = []\n",
    "# for i in y:\n",
    "#     if i=='whale':\n",
    "#         label.append(1)\n",
    "#     else:\n",
    "#         label.append(0)\n",
    "\n",
    "# tr_labes = np.array(label)\n",
    "tr_sp_lables = np.array(species_label_list)\n",
    "tr_sp_one_hot_label = to_categorical(tr_sp_lables)\n",
    "tr_sp_one_hot_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neumerical Label to Categorical for Individual Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T18:45:44.093507Z",
     "iopub.status.busy": "2022-04-11T18:45:44.092704Z",
     "iopub.status.idle": "2022-04-11T18:45:44.123249Z",
     "shell.execute_reply": "2022-04-11T18:45:44.12257Z",
     "shell.execute_reply.started": "2022-04-11T18:45:44.093465Z"
    }
   },
   "outputs": [],
   "source": [
    "individual_as_label = train_df['individual_id'].values\n",
    "individual_label_list = []\n",
    "for individual in individual_as_label:\n",
    "    individual_label_list.append(ids_to_neumeric[individual])\n",
    "# label = []\n",
    "# for i in y:\n",
    "#     if i=='whale':\n",
    "#         label.append(1)\n",
    "#     else:\n",
    "#         label.append(0)\n",
    "\n",
    "# tr_labes = np.array(label)\n",
    "tr_id_lables = np.array(individual_label_list)\n",
    "tr_id_one_hot_label = to_categorical(tr_id_lables)\n",
    "tr_id_one_hot_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into Train and validation set  for whale detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, tr_sp_one_hot_label, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into Train and validation set  for individual detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T18:45:51.08354Z",
     "iopub.status.busy": "2022-04-11T18:45:51.083021Z",
     "iopub.status.idle": "2022-04-11T18:45:51.569727Z",
     "shell.execute_reply": "2022-04-11T18:45:51.568871Z",
     "shell.execute_reply.started": "2022-04-11T18:45:51.083501Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, tr_id_one_hot_label, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model for whale detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(X_train, y_train, batch_size = 32,epochs=10,validation_data=(X_valid, y_valid)) #the batch size should be changed \n",
    "#according to the total input size if train image is very small and batch size is almost equal to train image numbers it will\n",
    "#return OOM -->out of memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('whale_detection_model.h5') \n",
    "model_h = tf.keras.models.load_model('whale_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.history['val_accuracy'])\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T18:45:59.456486Z",
     "iopub.status.busy": "2022-04-11T18:45:59.456156Z",
     "iopub.status.idle": "2022-04-11T18:46:17.673335Z",
     "shell.execute_reply": "2022-04-11T18:46:17.672418Z",
     "shell.execute_reply.started": "2022-04-11T18:45:59.45645Z"
    }
   },
   "outputs": [],
   "source": [
    "t_num = len(list_of_test_image_paths) #27956 number of images \n",
    "f_t_num = int(t_num/100) # trying to test for small number \n",
    "# for t_path in list_of_test_image_paths:#when all images will be tested \n",
    "X_test = test_data_generation(list_of_test_image_paths,f_t_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(probabilities))\n",
    "lsit = np.argmax(probabilities,axis = 1)\n",
    "inverse_species_to_neumeric = dict((v, k) for k, v in species_to_neumeric.items())\n",
    "for i in lsit:\n",
    "    print(inverse_species_to_neumeric[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,f_t_num):\n",
    "    re_img = resize_images(list_of_test_image_paths[i],image_w,image_h)\n",
    "    image = tf.cast(re_img, np.uint8)\n",
    "    print(list_of_test_image_paths[i])\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model for Individual detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T18:54:51.856977Z",
     "iopub.status.busy": "2022-04-11T18:54:51.856232Z",
     "iopub.status.idle": "2022-04-11T19:16:09.142694Z",
     "shell.execute_reply": "2022-04-11T19:16:09.141231Z",
     "shell.execute_reply.started": "2022-04-11T18:54:51.85694Z"
    }
   },
   "outputs": [],
   "source": [
    "model_history_ind = model_ind.fit(X_train, y_train, batch_size = 32,epochs=100,validation_data=(X_valid, y_valid)) #the batch size should be changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model_ind.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(probabilities))\n",
    "lsit = np.argmax(probabilities,axis = 1)\n",
    "inverse_ids_to_neumeric = dict((v, k) for k, v in ids_to_neumeric.items())\n",
    "for i in lsit:\n",
    "    print(inverse_ids_to_neumeric[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['individual_id'] == \"3cf81d69cc5911\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,f_t_num):\n",
    "    re_img = resize_images(list_of_test_image_paths[i],image_w,image_h)\n",
    "    image = tf.cast(re_img, np.uint8)\n",
    "    print(list_of_test_image_paths[i])\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the data for the individual training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_all['image_path'] = train_img_dir+'/'+train_df_all['image']\n",
    "# train_data_group_by_id = train_df_all.groupby('individual_id')\n",
    "train_data_group_by_id = train_df.groupby('individual_id')\n",
    "train_groups_array = dict()\n",
    "val_groups_array = []\n",
    "for g_index,group in train_data_group_by_id:\n",
    "    if(len(group) < 5):\n",
    "        val_groups_array.append(group)\n",
    "    else:\n",
    "        train_groups_array[g_index] = group\n",
    "# train_group_data_frame = pd.concat(train_groups_array) \n",
    "val_group_data_frame = pd.concat(val_groups_array)\n",
    "print(len(val_group_data_frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features by RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfor the image to numpy array for training \n",
    "#then fit a model per each individual\n",
    "def extract_resnet(X,image_h,image_w):  \n",
    "    # X : images numpy array\n",
    "    resnet_model = ResNet50(input_shape=(image_h, image_w, 3), weights='imagenet', include_top=False)  # Since top layer is the fc layer used for predictions\n",
    "    features_array = resnet_model.predict(X)\n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incomplete code for individual model and prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_array = dict()\n",
    "for key in train_groups_array.keys():\n",
    "    X_train_temp = train_data_genration(train_groups_array[key])\n",
    "    X_train_temp_features = extract_resnet(X_train_temp,image_h,image_w)\n",
    "    X_train_temp_features = X_train_temp_features.reshape(len(train_groups_array[key]),\n",
    "                                                          int(X_train_temp_features.size/len(train_groups_array[key])))\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train_temp_features)\n",
    "    X_train = ss.transform(X_train_temp_features)\n",
    "#     X_val = ss.transform(X_val)\n",
    "    # Take PCA to reduce feature space dimensionality\n",
    "    pca = PCA(n_components=len(train_groups_array[key]), whiten=True)# as the componant number min(number of sample, feature)\n",
    "    pca = pca.fit(X_train)\n",
    "#     print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "    X_train = pca.transform(X_train)\n",
    "#     X_val = pca.transform(X_val)\n",
    "    oc_svm_clf = svm.OneClassSVM(gamma=0.001, kernel='rbf', nu=0.08)  # Obtained using grid search\n",
    "    oc_svm_clf.fit(X_train)\n",
    "    model_array[key] = oc_svm_clf\n",
    "    test_image_batches = [list_of_test_image_paths[i:i + len(train_groups_array[key])] for i in range(0, len(list_of_test_image_paths),\n",
    "                                                                                 len(train_groups_array[key]))]\n",
    "    for batch in test_image_batches:\n",
    "        X_test_temp = test_data_generation(batch,len(batch))\n",
    "        X_test_temp_features = extract_resnet(X_test_temp,image_h,image_w)\n",
    "        X_test_temp_features = X_test_temp_features.reshape(len(train_groups_array[key]),\n",
    "                                                          int(X_test_temp_features.size/len(train_groups_array[key])))\n",
    "        X_test = ss.transform(X_test_temp_features)\n",
    "        X_test = pca.transform(X_test)\n",
    "        oc_svm_preds = oc_svm_clf.predict(X_test)\n",
    "#     if_preds = if_clf.predict(X_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tried other things not required now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaler to output from resnet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import resnet50\n",
    "\n",
    "for i in range(0,100):\n",
    "    test_image = load_img(list_of_test_image_paths[i], target_size = (image_h, image_w)) \n",
    "    test_np_image = img_to_array(test_image) \n",
    "    test_image_batch = np.expand_dims(test_np_image, axis = 0) \n",
    "    test_processed_image = resnet50.preprocess_input(test_image_batch.copy())\n",
    "#     ss = StandardScaler()\n",
    "#     test_processed_image = ss.transform(test_processed_image)\n",
    "    # Take PCA to reduce feature space dimensionality\n",
    "#     pca = PCA(n_components=512, whiten=True)\n",
    "#     pca = pca.fit(test_processed_image)\n",
    "#     test_processed_image = pca.transform(test_processed_image)\n",
    "    print(test_processed_image.shape)\n",
    "    test_processed_image = test_processed_image.reshape(1,image_h*image_w*3)\n",
    "\n",
    "    for key in model_array.keys():\n",
    "        oc_svm_preds = oc_svm_clf.predict(test_processed_image)\n",
    "        print(oc_svm_preds)\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
