{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved\n# as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of \n# the current session\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files\n# under the input directory\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport glob\nfrom tqdm import tqdm\nimport random\nimport os\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.applications.efficientnet as efn\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn import svm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T03:24:30.149453Z","iopub.execute_input":"2022-04-12T03:24:30.149829Z","iopub.status.idle":"2022-04-12T03:24:35.227030Z","shell.execute_reply.started":"2022-04-12T03:24:30.149749Z","shell.execute_reply":"2022-04-12T03:24:35.226278Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"image_h = 128\nimage_w = 128\nsample_size = 7000","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:35.228500Z","iopub.execute_input":"2022-04-12T03:24:35.228766Z","iopub.status.idle":"2022-04-12T03:24:35.235932Z","shell.execute_reply.started":"2022-04-12T03:24:35.228731Z","shell.execute_reply":"2022-04-12T03:24:35.234113Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read Directories","metadata":{}},{"cell_type":"code","source":"#print all file names\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename)) #end printing all file names\n\ntrain_img_dir = '/kaggle/input/happy-whale-and-dolphin/train_images'\ntest_img_dir = '/kaggle/input/happy-whale-and-dolphin/test_images'\nsub_path = '/kaggle/input/happy-whale-and-dolphin/sample_submission.csv'\ntrain_path = '/kaggle/input/happy-whale-and-dolphin/train.csv'","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:35.237395Z","iopub.execute_input":"2022-04-12T03:24:35.237817Z","iopub.status.idle":"2022-04-12T03:24:35.254227Z","shell.execute_reply.started":"2022-04-12T03:24:35.237782Z","shell.execute_reply":"2022-04-12T03:24:35.253514Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Label Inspection","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntrain_df.loc[train_df.species == \"bottlenose_dolpin\", \"species\"] = \"bottlenose_dolphin\"\ntrain_df.loc[train_df.species == \"kiler_whale\", \"species\"] = \"killer_whale\"\ntrain_df.loc[train_df.species == \"globis\", \"species\"] = \"short_finned_pilot_whale\"\ntrain_df.loc[train_df.species == \"pilot_whale\", \"species\"] = \"short_finned_pilot_whale\"\ntrain_df.loc[train_df.species == \"beluga\", \"species\"] = \"beluga_whale\"\ntrain_df.loc[train_df.species.str.contains(\"whale\")==True, \"label\"] = \"whale\"\ntrain_df.loc[train_df.species.str.contains(\"dolphin\")==True, \"label\"] = \"dolphin\"\n#the following can also be used however pd.np is deprecated in the future version \n# train_df['label'] = pd.np.where(train_df.species.str.contains(\"whale\"), \"whale\",\n#                    pd.np.where(train_df.species.str.contains(\"dolphin\"), \"dolphin\",\"task\"))\ntrain_df_all = train_df\ntrain_df = train_df.head(sample_size)\nprint(len(train_df['species'].unique()))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:39.003431Z","iopub.execute_input":"2022-04-12T03:24:39.004039Z","iopub.status.idle":"2022-04-12T03:24:39.192846Z","shell.execute_reply.started":"2022-04-12T03:24:39.004000Z","shell.execute_reply":"2022-04-12T03:24:39.192114Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Add image url","metadata":{}},{"cell_type":"code","source":"train_df['image_path'] = train_img_dir+'/'+train_df['image']\nlist_of_test_image_paths = glob.glob(test_img_dir+'/*')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:42.380055Z","iopub.execute_input":"2022-04-12T03:24:42.380910Z","iopub.status.idle":"2022-04-12T03:24:43.009262Z","shell.execute_reply.started":"2022-04-12T03:24:42.380862Z","shell.execute_reply":"2022-04-12T03:24:43.008531Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# String Label to neumeric lableing ","metadata":{}},{"cell_type":"code","source":"print(len(train_df['species'].unique()))\nlist_of_species = train_df['species'].unique()\nprint(train_df['species'].unique())\nspecies_to_neumeric = dict()\nfor i in range(0,len(list_of_species)):\n    species_to_neumeric[list_of_species[i]] = i","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:46.125224Z","iopub.execute_input":"2022-04-12T03:24:46.125471Z","iopub.status.idle":"2022-04-12T03:24:46.134849Z","shell.execute_reply.started":"2022-04-12T03:24:46.125442Z","shell.execute_reply":"2022-04-12T03:24:46.134051Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(len(train_df['individual_id'].unique()))\nlist_of_ids = train_df['individual_id'].unique()\nids_to_neumeric = dict()\nfor i in range(0,len(list_of_ids)):\n    ids_to_neumeric[list_of_ids[i]] = i","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:49.754030Z","iopub.execute_input":"2022-04-12T03:24:49.754749Z","iopub.status.idle":"2022-04-12T03:24:49.767401Z","shell.execute_reply.started":"2022-04-12T03:24:49.754713Z","shell.execute_reply":"2022-04-12T03:24:49.766417Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Image Pre-Processing\n1. Resizing the image\n2. Converting the colored image to greyscale image may be ","metadata":{}},{"cell_type":"code","source":"# #function to resize each image \n# def resize_images(path,image_w,image_h):#n_w =new width n_h = new_height\n#     img = tf.io.read_file(path)\n# #     img = tf.image.convert_image_dtype(img, tf.float32)\n#     img = tf.image.decode_jpeg(img, channels=3)#can decode to another format \n#     img = tf.image.resize(img, [image_w, image_h])\n#     return img\n# #concern After resizing it what we can do should we store the image to a new directory ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterate the images and resize and store in a numpy array","metadata":{}},{"cell_type":"code","source":"# N = len(train_df)\n# image_size = 128\n# image_train = np.empty((N, image_size, image_size, 3), dtype=np.uint8)\n# # loop through the images from the images ids from the target\\id dataset\n# # then grab the cooresponding image from disk, pre-process, and store in matrix in memory\n# for index,row in train_df.iterrows():\n#     re_img = resize_images(row.image_path,image_size,image_size)\n# #     image_train[i, :, :, :] = re_img\n# #     image = plt.imread(re_img) #after resizing It could not be plot \n#     #hence used tf casting to plot the image\n#     image = tf.cast(re_img, np.uint8)\n#     print((re_img.shape))\n#     plt.imshow(image)\n#     break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test data generation function ","metadata":{}},{"cell_type":"code","source":"def train_data_genration(train_df):#takes data frame input\n    train_image_list = []\n    for index,row in tqdm(train_df.iterrows()):\n    #     img = tf.io.read_file(row.image_path)\n    #     img = tf.image.decode_jpeg(img, channels=3)#can decode to another format \n    #     img = tf.image.resize(img, [128, 128])\n        img = tf.keras.preprocessing.image.load_img(row.image_path, target_size=(image_h,image_w,3), grayscale=False)\n        img = tf.keras.preprocessing.image.img_to_array(img)\n        img = img/255\n        train_image_list.append(img)\n    X_train = np.array(train_image_list)\n    return X_train\ndef test_data_generation(list_of_test_image_paths,f_t_num): #takes the image directory array and number of images\n    test_image_list = []\n    for i in tqdm(range(0,f_t_num)):\n        img = tf.keras.preprocessing.image.load_img(list_of_test_image_paths[i],\n                                                    target_size=(image_h,image_w,3), grayscale=False)\n        img = tf.keras.preprocessing.image.img_to_array(img)\n        img = img/255\n        test_image_list.append(img)\n    X_T = np.array(test_image_list)\n    return X_T","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:24:56.251037Z","iopub.execute_input":"2022-04-12T03:24:56.251841Z","iopub.status.idle":"2022-04-12T03:24:56.261093Z","shell.execute_reply.started":"2022-04-12T03:24:56.251792Z","shell.execute_reply":"2022-04-12T03:24:56.260360Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = train_data_genration(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:25:05.905000Z","iopub.execute_input":"2022-04-12T03:25:05.905881Z","iopub.status.idle":"2022-04-12T03:35:35.104679Z","shell.execute_reply.started":"2022-04-12T03:25:05.905832Z","shell.execute_reply":"2022-04-12T03:35:35.103918Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model For Identifying Whale and Dolphin","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = [image_h, image_w]\ndense_layer_size = len(species_to_neumeric.values())\nmodel = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(*IMAGE_SIZE, 3),\n                                                weights='imagenet',\n                                                include_top=False,classes=species_to_neumeric.values()),\n                             L.GlobalAveragePooling2D(),\n                             L.Flatten(),\n                             L.Dense(512, activation='relu'),\n                             L.Dense(dense_layer_size, activation='softmax')])\nmodel.compile(optimizer='adam',\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy']\n             )\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T04:25:25.181535Z","iopub.execute_input":"2022-04-12T04:25:25.181864Z","iopub.status.idle":"2022-04-12T04:25:25.266127Z","shell.execute_reply.started":"2022-04-12T04:25:25.181776Z","shell.execute_reply":"2022-04-12T04:25:25.265052Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Model for individual Detection","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = [image_h, image_w]\ndense_layer_size = len(ids_to_neumeric.values())\nmodel_ind = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(*IMAGE_SIZE, 3),\n                                                weights='imagenet',\n                                                include_top=False,classes=ids_to_neumeric.values()),\n                             L.GlobalAveragePooling2D(),\n                             L.Flatten(),\n                             L.Dense(512, activation='relu'),\n                             L.Dense(dense_layer_size, activation='softmax')])\nmodel_ind.compile(optimizer='adam',\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy']\n             )\nmodel_ind.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:45:21.222946Z","iopub.execute_input":"2022-04-11T18:45:21.223225Z","iopub.status.idle":"2022-04-11T18:45:29.230811Z","shell.execute_reply.started":"2022-04-11T18:45:21.223194Z","shell.execute_reply":"2022-04-11T18:45:29.229966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neumerical Label to Categorical for Whale & Dolphin Detection","metadata":{}},{"cell_type":"code","source":"species_as_label = train_df['species'].values\nspecies_label_list = []\nfor species in species_as_label:\n    species_label_list.append(species_to_neumeric[species])\n# label = []\n# for i in y:\n#     if i=='whale':\n#         label.append(1)\n#     else:\n#         label.append(0)\n\n# tr_labes = np.array(label)\ntr_sp_lables = np.array(species_label_list)\ntr_sp_one_hot_label = to_categorical(tr_sp_lables)\ntr_sp_one_hot_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neumerical Label to Categorical for Individual Detection","metadata":{}},{"cell_type":"code","source":"individual_as_label = train_df['individual_id'].values\nindividual_label_list = []\nfor individual in individual_as_label:\n    individual_label_list.append(ids_to_neumeric[individual])\n# label = []\n# for i in y:\n#     if i=='whale':\n#         label.append(1)\n#     else:\n#         label.append(0)\n\n# tr_labes = np.array(label)\ntr_id_lables = np.array(individual_label_list)\ntr_id_one_hot_label = to_categorical(tr_id_lables)\ntr_id_one_hot_label","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:45:44.092704Z","iopub.execute_input":"2022-04-11T18:45:44.093507Z","iopub.status.idle":"2022-04-11T18:45:44.123249Z","shell.execute_reply.started":"2022-04-11T18:45:44.093465Z","shell.execute_reply":"2022-04-11T18:45:44.12257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divide into Train and validation set  for whale detection","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, tr_sp_one_hot_label, random_state=42, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divide into Train and validation set  for individual detection","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, tr_id_one_hot_label, random_state=42, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:45:51.083021Z","iopub.execute_input":"2022-04-11T18:45:51.08354Z","iopub.status.idle":"2022-04-11T18:45:51.569727Z","shell.execute_reply.started":"2022-04-11T18:45:51.083501Z","shell.execute_reply":"2022-04-11T18:45:51.568871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model for whale detection","metadata":{}},{"cell_type":"code","source":"model_history = model.fit(X_train, y_train, batch_size = 32,epochs=10,validation_data=(X_valid, y_valid)) #the batch size should be changed \n#according to the total input size if train image is very small and batch size is almost equal to train image numbers it will\n#return OOM -->out of memory error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('whale_detection_model.h5') \nmodel_h = tf.keras.models.load_model('whale_detection_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(model.history['val_accuracy'])\n# summarize history for accuracy\nplt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_num = len(list_of_test_image_paths) #27956 number of images \nf_t_num = int(t_num/100) # trying to test for small number \n# for t_path in list_of_test_image_paths:#when all images will be tested \nX_test = test_data_generation(list_of_test_image_paths,f_t_num)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:45:59.456156Z","iopub.execute_input":"2022-04-11T18:45:59.456486Z","iopub.status.idle":"2022-04-11T18:46:17.673335Z","shell.execute_reply.started":"2022-04-11T18:45:59.45645Z","shell.execute_reply":"2022-04-11T18:46:17.672418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probabilities = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(probabilities))\nlsit = np.argmax(probabilities,axis = 1)\ninverse_species_to_neumeric = dict((v, k) for k, v in species_to_neumeric.items())\nfor i in lsit:\n    print(inverse_species_to_neumeric[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,f_t_num):\n    re_img = resize_images(list_of_test_image_paths[i],image_w,image_h)\n    image = tf.cast(re_img, np.uint8)\n    print(list_of_test_image_paths[i])\n    plt.imshow(image)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model for Individual detection","metadata":{}},{"cell_type":"code","source":"model_history_ind = model_ind.fit(X_train, y_train, batch_size = 32,epochs=100,validation_data=(X_valid, y_valid)) #the batch size should be changed ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:54:51.856232Z","iopub.execute_input":"2022-04-11T18:54:51.856977Z","iopub.status.idle":"2022-04-11T19:16:09.142694Z","shell.execute_reply.started":"2022-04-11T18:54:51.85694Z","shell.execute_reply":"2022-04-11T19:16:09.141231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probabilities = model_ind.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(probabilities))\nlsit = np.argmax(probabilities,axis = 1)\ninverse_ids_to_neumeric = dict((v, k) for k, v in ids_to_neumeric.items())\nfor i in lsit:\n    print(inverse_ids_to_neumeric[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df[train_df['individual_id'] == \"3cf81d69cc5911\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,f_t_num):\n    re_img = resize_images(list_of_test_image_paths[i],image_w,image_h)\n    image = tf.cast(re_img, np.uint8)\n    print(list_of_test_image_paths[i])\n    plt.imshow(image)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Separating the data for the individual training ","metadata":{}},{"cell_type":"code","source":"# train_df_all['image_path'] = train_img_dir+'/'+train_df_all['image']\n# train_data_group_by_id = train_df_all.groupby('individual_id')\ntrain_data_group_by_id = train_df.groupby('individual_id')\ntrain_groups_array = dict()\nval_groups_array = []\nfor g_index,group in train_data_group_by_id:\n    if(len(group) < 5):\n        val_groups_array.append(group)\n    else:\n        train_groups_array[g_index] = group\n# train_group_data_frame = pd.concat(train_groups_array) \nval_group_data_frame = pd.concat(val_groups_array)\nprint(len(val_group_data_frame))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract features by RESNET50","metadata":{}},{"cell_type":"code","source":"#transfor the image to numpy array for training \n#then fit a model per each individual\ndef extract_resnet(X,image_h,image_w):  \n    # X : images numpy array\n    resnet_model = ResNet50(input_shape=(image_h, image_w, 3), weights='imagenet', include_top=False)  # Since top layer is the fc layer used for predictions\n    features_array = resnet_model.predict(X)\n    return features_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Incomplete code for individual model and prediction ","metadata":{}},{"cell_type":"code","source":"model_array = dict()\nfor key in train_groups_array.keys():\n    X_train_temp = train_data_genration(train_groups_array[key])\n    X_train_temp_features = extract_resnet(X_train_temp,image_h,image_w)\n    X_train_temp_features = X_train_temp_features.reshape(len(train_groups_array[key]),\n                                                          int(X_train_temp_features.size/len(train_groups_array[key])))\n    ss = StandardScaler()\n    ss.fit(X_train_temp_features)\n    X_train = ss.transform(X_train_temp_features)\n#     X_val = ss.transform(X_val)\n    # Take PCA to reduce feature space dimensionality\n    pca = PCA(n_components=len(train_groups_array[key]), whiten=True)# as the componant number min(number of sample, feature)\n    pca = pca.fit(X_train)\n#     print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n    X_train = pca.transform(X_train)\n#     X_val = pca.transform(X_val)\n    oc_svm_clf = svm.OneClassSVM(gamma=0.001, kernel='rbf', nu=0.08)  # Obtained using grid search\n    oc_svm_clf.fit(X_train)\n    model_array[key] = oc_svm_clf\n    test_image_batches = [list_of_test_image_paths[i:i + len(train_groups_array[key])] for i in range(0, len(list_of_test_image_paths),\n                                                                                 len(train_groups_array[key]))]\n    for batch in test_image_batches:\n        X_test_temp = test_data_generation(batch,len(batch))\n        X_test_temp_features = extract_resnet(X_test_temp,image_h,image_w)\n        X_test_temp_features = X_test_temp_features.reshape(len(train_groups_array[key]),\n                                                          int(X_test_temp_features.size/len(train_groups_array[key])))\n        X_test = ss.transform(X_test_temp_features)\n        X_test = pca.transform(X_test)\n        oc_svm_preds = oc_svm_clf.predict(X_test)\n#     if_preds = if_clf.predict(X_test)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tried other things not required now","metadata":{}},{"cell_type":"code","source":"# Apply standard scaler to output from resnet50\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications import resnet50\n\nfor i in range(0,100):\n    test_image = load_img(list_of_test_image_paths[i], target_size = (image_h, image_w)) \n    test_np_image = img_to_array(test_image) \n    test_image_batch = np.expand_dims(test_np_image, axis = 0) \n    test_processed_image = resnet50.preprocess_input(test_image_batch.copy())\n#     ss = StandardScaler()\n#     test_processed_image = ss.transform(test_processed_image)\n    # Take PCA to reduce feature space dimensionality\n#     pca = PCA(n_components=512, whiten=True)\n#     pca = pca.fit(test_processed_image)\n#     test_processed_image = pca.transform(test_processed_image)\n    print(test_processed_image.shape)\n    test_processed_image = test_processed_image.reshape(1,image_h*image_w*3)\n\n    for key in model_array.keys():\n        oc_svm_preds = oc_svm_clf.predict(test_processed_image)\n        print(oc_svm_preds)\n    break\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}